{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D963hPkd_d7b",
        "outputId": "da41b34e-b464-4c08-ad5c-9ef741ee2f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "YATR6X4GAdb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"API Key not found! Please store it using userdata.set('GROQ_API_KEY', 'your-api-key')\")\n"
      ],
      "metadata": {
        "id": "2c4dc2zpAghV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://api.groq.com/openai/v1/models\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}"
      ],
      "metadata": {
        "id": "rKUM_mQ_A8Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the models\n",
        "response = requests.get(url, headers=headers, verify=True)\n",
        "if response.status_code == 200:\n",
        "    available_models = response.json()\n",
        "    print(\"Available Models:\", available_models)\n",
        "else:\n",
        "    print(f\"Error fetching models: {response.status_code} - {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0xkIPqgA_Jc",
        "outputId": "f1d4b3c2-31a4-4c42-a4b2-bc3e1e28a659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Models: {'object': 'list', 'data': [{'id': 'qwen-qwq-32b', 'object': 'model', 'created': 1741214760, 'owned_by': 'Alibaba Cloud', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'whisper-large-v3-turbo', 'object': 'model', 'created': 1728413088, 'owned_by': 'OpenAI', 'active': True, 'context_window': 448, 'public_apps': None}, {'id': 'deepseek-r1-distill-llama-70b', 'object': 'model', 'created': 1737924940, 'owned_by': 'DeepSeek / Meta', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'llama-3.3-70b-specdec', 'object': 'model', 'created': 1733505017, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama-guard-3-8b', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama3-70b-8192', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama3-8b-8192', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama-3.2-3b-preview', 'object': 'model', 'created': 1727224290, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama-3.3-70b-versatile', 'object': 'model', 'created': 1733447754, 'owned_by': 'Meta', 'active': True, 'context_window': 32768, 'public_apps': None}, {'id': 'llama-3.2-1b-preview', 'object': 'model', 'created': 1727224268, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'llama-3.2-90b-vision-preview', 'object': 'model', 'created': 1727226914, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'gemma2-9b-it', 'object': 'model', 'created': 1693721698, 'owned_by': 'Google', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'allam-2-7b', 'object': 'model', 'created': 1737672203, 'owned_by': 'SDAIA', 'active': True, 'context_window': 4096, 'public_apps': None}, {'id': 'qwen-2.5-32b', 'object': 'model', 'created': 1738789898, 'owned_by': 'Alibaba Cloud', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'whisper-large-v3', 'object': 'model', 'created': 1693721698, 'owned_by': 'OpenAI', 'active': True, 'context_window': 448, 'public_apps': None}, {'id': 'llama-3.1-8b-instant', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'distil-whisper-large-v3-en', 'object': 'model', 'created': 1693721698, 'owned_by': 'Hugging Face', 'active': True, 'context_window': 448, 'public_apps': None}, {'id': 'qwen-2.5-coder-32b', 'object': 'model', 'created': 1739494572, 'owned_by': 'Alibaba Cloud', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'deepseek-r1-distill-qwen-32b', 'object': 'model', 'created': 1738891590, 'owned_by': 'DeepSeek / Alibaba Cloud', 'active': True, 'context_window': 131072, 'public_apps': None}, {'id': 'llama-3.2-11b-vision-preview', 'object': 'model', 'created': 1727226869, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None}, {'id': 'mistral-saba-24b', 'object': 'model', 'created': 1739996492, 'owned_by': 'Mistral AI', 'active': True, 'context_window': 32768, 'public_apps': None}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"llama3-70b-8192\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}]\n",
        "}"
      ],
      "metadata": {
        "id": "siYCevnZBQjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.post(endpoint, headers=headers, json=payload, verify=True)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"\\nAssistant Response:\\n\", data[\"choices\"][0][\"message\"][\"content\"])\n",
        "else:\n",
        "    print(f\"Error {response.status_code}: {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vsNk_25BVZC",
        "outputId": "cd77da2b-1182-42da-d898-ecffb1e7db4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assistant Response:\n",
            " Fast language models have gained significant importance in recent years due to their ability to process and analyze vast amounts of text data quickly and efficiently. Here are some reasons why fast language models are important:\n",
            "\n",
            "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to provide immediate responses to user queries.\n",
            "2. **Scalability**: Fast language models can handle large volumes of text data, making them essential for applications that require processing massive amounts of data, such as social media monitoring, customer feedback analysis, and sentiment analysis.\n",
            "3. **Improved User Experience**: Fast language models provide rapid response times, which lead to a better user experience in applications such as search engines, recommender systems, and question-answering systems.\n",
            "4. **Efficient Resource Utilization**: Fast language models require less computational resources and energy, making them more environmentally friendly and cost-effective.\n",
            "5. **Enhanced Security**: Fast language models can quickly identify and respond to security threats, such as malware, phishing attacks, and spam detection.\n",
            "6. **Research and Development**: Fast language models accelerate research and development in natural language processing (NLP) by enabling faster experimentation, prototyping, and testing of new models and techniques.\n",
            "7. **Deployment in Resource-Constrained Environments**: Fast language models can be deployed in resource-constrained environments, such as edge devices, IoT devices, and mobile devices, where computational resources are limited.\n",
            "8. **Improved Accuracy**: Fast language models can lead to improved accuracy by enabling the processing of larger datasets, which can lead to better model performance and generalization.\n",
            "9. **Multitasking and Multimodal Processing**: Fast language models can handle multiple tasks simultaneously, such as language translation, sentiment analysis, and question-answering, and can process multiple modalities of input, such as text, speech, and images.\n",
            "10. **Edge Cases and Rare Events**: Fast language models can quickly identify and respond to edge cases and rare events, such as detecting rare medical conditions or identifying fraudulent activities.\n",
            "11. **Personalization and Customization**: Fast language models enable personalization and customization of applications, such as recommending products based on user preferences and behavior.\n",
            "12. **Compliance and Regulatory Requirements**: Fast language models can help organizations comply with regulatory requirements, such as GDPR and CCPA, by quickly identifying and responding to sensitive information.\n",
            "\n",
            "In summary, fast language models are essential for many applications that require quick analysis and response to large amounts of text data. They enable real-time applications, improve user experience, and facilitate research and development in NLP.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}